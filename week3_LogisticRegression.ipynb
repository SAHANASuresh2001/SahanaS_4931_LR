{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2b5d5e",
   "metadata": {
    "id": "ba2b5d5e"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d13cc6a",
   "metadata": {
    "id": "5d13cc6a"
   },
   "outputs": [],
   "source": [
    "d = datasets.load_breast_cancer()\n",
    "x, y = d.data, d.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834d41f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "834d41f4",
    "outputId": "d4a05e38-9339-4bbf-d88f-6e71bb328580"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451f24cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "451f24cd",
    "outputId": "37a60cb9-a905-411e-9f37-7315022297f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31cbee1",
   "metadata": {
    "id": "b31cbee1"
   },
   "outputs": [],
   "source": [
    "# defining a fuction for train -test split\n",
    "\n",
    "def split_data(X, y, test_size=0.2, random_state=0):\n",
    "    np.random.seed(random_state)                  \n",
    "    #set the seed for reproducible results\n",
    "    indices = np.random.permutation(len(X))       \n",
    "    #shuffling the indices        \n",
    "    data_test_size = int(X.shape[0] * test_size)  \n",
    "    #Get the test size\n",
    "\n",
    "    #Separating the Independent and Dependent features into the Train and Test Set\n",
    "    train_indices = indices[data_test_size:]\n",
    "    test_indices = indices[:data_test_size]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d509e1",
   "metadata": {
    "id": "01d509e1"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=100000, y_pred = None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.bias = None\n",
    "        self.weights = None\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "            n_samples, n_features= X.shape\n",
    "            self.weights=np.zeros(n_features)\n",
    "            self.bias=0\n",
    "            \n",
    "                \n",
    "            for i in range(self.num_iterations):\n",
    "                    linear_pred = np.dot(X, self.weights) + self.bias\n",
    "                    predictions = self.sigmoid(linear_pred)\n",
    "                    #error = -1/size * np.sum(y * np.log(predictions)) + (1 - y) * np.log(1-sigma)\n",
    "                \n",
    "                    # calculating gradient for weight and bias)\n",
    "                   # print(np.dot(X.T, error))\n",
    "                    dw = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "                    #\n",
    "                   # print(dw)\n",
    "                    db = (1/n_samples) * np.sum(predictions - y)\n",
    "                \n",
    "                \n",
    "                    # for updating weights and bias\n",
    "                    self.weights -= self.learning_rate * dw\n",
    "                    self.bias -= self.learning_rate * db\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        Z = np.dot(X, self.weights) + self.bias\n",
    "        LR = self.sigmoid(Z)\n",
    "        class_pred = [1 if y > 0.5 else 0 for y in LR]\n",
    "        return np.array(class_pred)\n",
    "\n",
    "\n",
    "    def accuracy_score(self, y_test, y_pred):\n",
    "        \"\"\"Calculate the accuracy score for a set of predictions.\"\"\"\n",
    "        n_correct = np.sum(y_test == y_pred)\n",
    "        n_total = len(y_test)\n",
    "        accuracy = n_correct / n_total\n",
    "        return accuracy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f5b329f",
   "metadata": {
    "id": "4f5b329f"
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "X_train, y_train, X_test, y_test = split_data(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8291f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc8291f1",
    "outputId": "163394b3-6ba6-4816-f786-c54ce93ecc31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahana s\\AppData\\Local\\Temp\\ipykernel_33388\\535949788.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "248aedf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "248aedf9",
    "outputId": "34a56864-b67e-41b3-bf56-1ae7fd8b1431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8584070796460177\n"
     ]
    }
   ],
   "source": [
    "acc = model.accuracy_score (y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NG7xT4qqLQF9",
   "metadata": {
    "id": "NG7xT4qqLQF9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
